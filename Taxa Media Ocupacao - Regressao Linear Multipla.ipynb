{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8267469",
   "metadata": {},
   "source": [
    "# <font color='blue'> Regressão Linear Múltipla - Python\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8707a5bf",
   "metadata": {},
   "source": [
    "## Definindo o Problema de Negócio\n",
    "\n",
    "Nosso objetivo é construir um modelo de Machine Learning que seja capaz de fazer previsões sobre a taxa média de ocupação de casas na região de Boston, EUA, por proprietários. A variável a ser prevista é um valor numérico que representa a mediana da taxa de ocupação das casas em Boston. Para cada casa temos diversas variáveis explanatórias. Sendo assim, podemos resolver este problema empregando Regressão Linear Simples ou Múltipla."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b502fc",
   "metadata": {},
   "source": [
    "## Definindo o Dataset \n",
    "\n",
    "Usaremos o Boston Housing Dataset, que é um conjunto de dados que tem a taxa média de ocupação das casas, juntamente com outras 13 variáveis que podem estar relacionadas aos preços das casas. Esses são os fatores como condições socioeconômicas, condições ambientais, instalações educacionais e alguns outros fatores semelhantes. Existem 506 observações nos dados para 14 variáveis. Existem 12 variáveis numéricas em nosso conjunto de dados e 1 variável categórica. O objetivo deste projeto é construir um modelo de regressão linear para estimar a taxa média de ocupação das casas pelos proprietários em Boston."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348d5c50",
   "metadata": {},
   "source": [
    "\n",
    "- Fonte: https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
    "\n",
    "- CRIM: per capita crime rate by town\n",
    "- ZN: proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- INDUS: proportion of non-retail business acres per town\n",
    "- CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- NOX: nitric oxides concentration (parts per 10 million)\n",
    "- RM: average number of rooms per \n",
    "\n",
    "- AGE: proportion of owner-occupied units built prior to 1940\n",
    "- DIS: weighted distances to five Boston employment centres\n",
    "- RAD: index of accessibility to radial highways\n",
    "- TAX: full-value property-tax rate per 10,000\n",
    "- PTRATIO: pupil-teacher ratio by town\n",
    "- B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- LSTAT: % lower status of the population\n",
    "- <font color='red'>TARGET: Median value of owner-occupied homes in $1000's</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bca5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dafaba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataset\n",
    "boston = load_boston()\n",
    "dataset = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "dataset['target'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aecdf158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando número de observações e variáveis\n",
    "observations = len(dataset)\n",
    "variables = dataset.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8438c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coletando x e y\n",
    "X = dataset.iloc[:,:-1]\n",
    "y = dataset['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2f84ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variáveis explanatórias\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae1ad80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variável target\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b76c1f",
   "metadata": {},
   "source": [
    "## Usando Múltiplos Atributos com StatsModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38d8e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do modelo\n",
    "Xc = sm.add_constant(X)\n",
    "modelo = sm.OLS(y, Xc)\n",
    "modelo_v1 = modelo.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0055982e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.741</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   108.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 31 Aug 2022</td> <th>  Prob (F-statistic):</th> <td>6.72e-135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:05:54</td>     <th>  Log-Likelihood:    </th> <td> -1498.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3026.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>   3085.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>   36.4595</td> <td>    5.103</td> <td>    7.144</td> <td> 0.000</td> <td>   26.432</td> <td>   46.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRIM</th>    <td>   -0.1080</td> <td>    0.033</td> <td>   -3.287</td> <td> 0.001</td> <td>   -0.173</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZN</th>      <td>    0.0464</td> <td>    0.014</td> <td>    3.382</td> <td> 0.001</td> <td>    0.019</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>   <td>    0.0206</td> <td>    0.061</td> <td>    0.334</td> <td> 0.738</td> <td>   -0.100</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>    <td>    2.6867</td> <td>    0.862</td> <td>    3.118</td> <td> 0.002</td> <td>    0.994</td> <td>    4.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NOX</th>     <td>  -17.7666</td> <td>    3.820</td> <td>   -4.651</td> <td> 0.000</td> <td>  -25.272</td> <td>  -10.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>      <td>    3.8099</td> <td>    0.418</td> <td>    9.116</td> <td> 0.000</td> <td>    2.989</td> <td>    4.631</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE</th>     <td>    0.0007</td> <td>    0.013</td> <td>    0.052</td> <td> 0.958</td> <td>   -0.025</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>     <td>   -1.4756</td> <td>    0.199</td> <td>   -7.398</td> <td> 0.000</td> <td>   -1.867</td> <td>   -1.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD</th>     <td>    0.3060</td> <td>    0.066</td> <td>    4.613</td> <td> 0.000</td> <td>    0.176</td> <td>    0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX</th>     <td>   -0.0123</td> <td>    0.004</td> <td>   -3.280</td> <td> 0.001</td> <td>   -0.020</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th> <td>   -0.9527</td> <td>    0.131</td> <td>   -7.283</td> <td> 0.000</td> <td>   -1.210</td> <td>   -0.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>       <td>    0.0093</td> <td>    0.003</td> <td>    3.467</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>   <td>   -0.5248</td> <td>    0.051</td> <td>  -10.347</td> <td> 0.000</td> <td>   -0.624</td> <td>   -0.425</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>178.041</td> <th>  Durbin-Watson:     </th> <td>   1.078</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 783.126</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.521</td>  <th>  Prob(JB):          </th> <td>8.84e-171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.281</td>  <th>  Cond. No.          </th> <td>1.51e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.51e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.741\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     108.1\n",
       "Date:                Wed, 31 Aug 2022   Prob (F-statistic):          6.72e-135\n",
       "Time:                        12:05:54   Log-Likelihood:                -1498.8\n",
       "No. Observations:                 506   AIC:                             3026.\n",
       "Df Residuals:                     492   BIC:                             3085.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         36.4595      5.103      7.144      0.000      26.432      46.487\n",
       "CRIM          -0.1080      0.033     -3.287      0.001      -0.173      -0.043\n",
       "ZN             0.0464      0.014      3.382      0.001       0.019       0.073\n",
       "INDUS          0.0206      0.061      0.334      0.738      -0.100       0.141\n",
       "CHAS           2.6867      0.862      3.118      0.002       0.994       4.380\n",
       "NOX          -17.7666      3.820     -4.651      0.000     -25.272     -10.262\n",
       "RM             3.8099      0.418      9.116      0.000       2.989       4.631\n",
       "AGE            0.0007      0.013      0.052      0.958      -0.025       0.027\n",
       "DIS           -1.4756      0.199     -7.398      0.000      -1.867      -1.084\n",
       "RAD            0.3060      0.066      4.613      0.000       0.176       0.436\n",
       "TAX           -0.0123      0.004     -3.280      0.001      -0.020      -0.005\n",
       "PTRATIO       -0.9527      0.131     -7.283      0.000      -1.210      -0.696\n",
       "B              0.0093      0.003      3.467      0.001       0.004       0.015\n",
       "LSTAT         -0.5248      0.051    -10.347      0.000      -0.624      -0.425\n",
       "==============================================================================\n",
       "Omnibus:                      178.041   Durbin-Watson:                   1.078\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              783.126\n",
       "Skew:                           1.521   Prob(JB):                    8.84e-171\n",
       "Kurtosis:                       8.281   Cond. No.                     1.51e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.51e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_v1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc82e31",
   "metadata": {},
   "source": [
    "### Matriz de Correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7418df4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
      "CRIM     1.000000 -0.200469  0.406583 -0.055892  0.420972 -0.219247  0.352734   \n",
      "ZN      -0.200469  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \n",
      "INDUS    0.406583 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \n",
      "CHAS    -0.055892 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \n",
      "NOX      0.420972 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \n",
      "RM      -0.219247  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \n",
      "AGE      0.352734 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \n",
      "DIS     -0.379670  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \n",
      "RAD      0.625505 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \n",
      "TAX      0.582764 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \n",
      "PTRATIO  0.289946 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \n",
      "B       -0.385064  0.175520 -0.356977  0.048788 -0.380051  0.128069 -0.273534   \n",
      "LSTAT    0.455621 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \n",
      "\n",
      "              DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
      "CRIM    -0.379670  0.625505  0.582764  0.289946 -0.385064  0.455621  \n",
      "ZN       0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.412995  \n",
      "INDUS   -0.708027  0.595129  0.720760  0.383248 -0.356977  0.603800  \n",
      "CHAS    -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.053929  \n",
      "NOX     -0.769230  0.611441  0.668023  0.188933 -0.380051  0.590879  \n",
      "RM       0.205246 -0.209847 -0.292048 -0.355501  0.128069 -0.613808  \n",
      "AGE     -0.747881  0.456022  0.506456  0.261515 -0.273534  0.602339  \n",
      "DIS      1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.496996  \n",
      "RAD     -0.494588  1.000000  0.910228  0.464741 -0.444413  0.488676  \n",
      "TAX     -0.534432  0.910228  1.000000  0.460853 -0.441808  0.543993  \n",
      "PTRATIO -0.232471  0.464741  0.460853  1.000000 -0.177383  0.374044  \n",
      "B        0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.366087  \n",
      "LSTAT   -0.496996  0.488676  0.543993  0.374044 -0.366087  1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Gerando a matriz\n",
    "X = dataset.iloc[:,:-1]\n",
    "matriz_corr = X.corr()\n",
    "print (matriz_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbf53758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um Correlation Plot\n",
    "def visualize_correlation_matrix(data, hurdle = 0.0):\n",
    "    R = np.corrcoef(data, rowvar = 0)\n",
    "    R[np.where(np.abs(R) < hurdle)] = 0.0\n",
    "    heatmap = plt.pcolor(R, cmap = mpl.cm.coolwarm, alpha = 0.8)\n",
    "    heatmap.axes.set_frame_on(False)\n",
    "    heatmap.axes.set_yticks(np.arange(R.shape[0]) + 0.5, minor = False)\n",
    "    heatmap.axes.set_xticks(np.arange(R.shape[1]) + 0.5, minor = False)\n",
    "    heatmap.axes.set_xticklabels(variables, minor = False)\n",
    "    plt.xticks(rotation=90)\n",
    "    heatmap.axes.set_yticklabels(variables, minor = False)\n",
    "    plt.tick_params(axis = 'both', which = 'both', bottom = 'off', top = 'off', left = 'off', right = 'off') \n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06a82f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizando o Plot\n",
    "visualize_correlation_matrix(X, hurdle = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7ab3a3",
   "metadata": {},
   "source": [
    "## Avaliando a Multicolinearidade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a2ead0",
   "metadata": {},
   "source": [
    "### Autovalores (Eigenvalues) e Autovetores (Eigenvectors)\n",
    "- Uma forma ainda mais automática de detectar associações multicolineares (e descobrir problemas numéricos em uma inversão de matriz) é usar autovetores. Explicados em termos simples, os autovetores são uma maneira muito inteligente de recombinar a variância entre as variáveis, criando novos recursos acumulando toda a variância compartilhada. Tal recombinação pode ser obtida usando a função NumPy linalg.eig, resultando em um vetor de autovalores (representando a quantidade de variância recombinada para cada nova variável) e autovetores (uma matriz nos dizendo como as novas variáveis se relacionam com as antigas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ee26ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando eigenvalues e eigenvectors\n",
    "corr = np.corrcoef(X, rowvar = 0)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc5d204",
   "metadata": {},
   "source": [
    "- Depois de extrair os autovalores, imprimimos em ordem decrescente e procuramos qualquer elemento cujo valor seja próximo de zero ou pequeno em comparação com os outros. Valores próximos a zero podem representar um problema real para equações normais e outros métodos de otimização baseados na inversão matricial. Valores pequenos representam uma fonte elevada, mas não crítica, de multicolinearidade. Se você detectar qualquer um desses valores baixos, anote a posição no vetor (lembre-se que os índices em Python começam por zero). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b3864b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.12684883 1.43327512 1.24261667 0.85757511 0.83481594 0.65740718\n",
      " 0.53535609 0.39609731 0.06350926 0.27694333 0.16930298 0.18601437\n",
      " 0.22023782]\n"
     ]
    }
   ],
   "source": [
    "print (eigenvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535edd0",
   "metadata": {},
   "source": [
    "- Usando a posição do índice na lista de autovalores, podemos encontrar o vetor específico nos autovetores que contém as variáveis carregadas, ou seja, o nível de associação com os valores originais. No eigenvector, observamos valores nas posições de índice 2, 8 e 9, que estão realmente em destaque em termos de valor absoluto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7219e55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0459523   0.08091897  0.25107654 -0.03592171 -0.04363045 -0.0455671\n",
      "  0.03855068  0.01829854  0.63348972 -0.72023345 -0.02339805  0.00446307\n",
      " -0.02443168]\n"
     ]
    }
   ],
   "source": [
    "print (eigenvectors[:,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd51f2f",
   "metadata": {},
   "source": [
    "- Agora nós imprimimos os nomes das variáveis para saber quais contribuem mais com seus valores para construir o autovetor. Associamos o vetor de variáveis com o eigenvector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81bdf800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDUS RAD TAX\n"
     ]
    }
   ],
   "source": [
    "print (variables[2], variables[8], variables[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d40662",
   "metadata": {},
   "source": [
    "- Tendo encontrado os culpados da multicolinearidade, o que devemos fazer com essas variáveis? A remoção de algumas delas é geralmente a melhor solução."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45416bc0",
   "metadata": {},
   "source": [
    "## Gradiente Descendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b9a2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando os dados\n",
    "observations = len(dataset)\n",
    "variables = dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7132a60d",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "- Podemos aplicar Feature Scaling através de Padronização ou Normalização. Normalização aplica escala aos dados com intervalos entre 0 e 1. A Padronização divide a média pelo desvio padrão para obter uma unidade de variância. Vamos usar a Padronização (StandardScaler) pois nesse caso esta técnica ajusta os coeficientes e torna a superfície de erros mais \"tratável\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30415776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando Padronização\n",
    "standardization = StandardScaler()\n",
    "Xst = standardization.fit_transform(X)\n",
    "original_means = standardization.mean_\n",
    "originanal_stds = standardization.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "631ad539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando X e Y\n",
    "Xst = np.column_stack((Xst,np.ones(observations)))\n",
    "y  = dataset['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abbfecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def random_w( p ):\n",
    "    return np.array([np.random.normal() for j in range(p)])\n",
    "\n",
    "def hypothesis(X,w):\n",
    "    return np.dot(X,w)\n",
    "\n",
    "def loss(X,w,y):\n",
    "    return hypothesis(X,w) - y\n",
    "\n",
    "def squared_loss(X,w,y):\n",
    "    return loss(X,w,y)**2\n",
    "\n",
    "def gradient(X,w,y):\n",
    "    gradients = list()\n",
    "    n = float(len( y ))\n",
    "    for j in range(len(w)):\n",
    "        gradients.append(np.sum(loss(X,w,y) * X[:,j]) / n)\n",
    "    return gradients\n",
    "\n",
    "def update(X,w,y, alpha = 0.01):\n",
    "    return [t - alpha*g for t, g in zip(w, gradient(X,w,y))]\n",
    "\n",
    "def optimize(X,y, alpha = 0.01, eta = 10**-12, iterations = 1000):\n",
    "    w = random_w(X.shape[1])\n",
    "    path = list()\n",
    "    for k in range(iterations):\n",
    "        SSL = np.sum(squared_loss(X,w,y))\n",
    "        new_w = update(X,w,y, alpha = alpha)\n",
    "        new_SSL = np.sum(squared_loss(X,new_w,y))\n",
    "        w = new_w\n",
    "        if k>=5 and (new_SSL - SSL <= eta and new_SSL - SSL >= -eta):\n",
    "            path.append(new_SSL)\n",
    "            return w, path\n",
    "        if k % (iterations / 20) == 0:\n",
    "            path.append(new_SSL)\n",
    "    return w, path                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c19d0b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes finais padronizados: -0.9281, 1.0816, 0.1409, 0.6817, -2.0567, 2.6742, 0.0195, -3.1040, 2.6622, -2.0768, -2.0606, 0.8493, -3.7436, 22.5328\n"
     ]
    }
   ],
   "source": [
    "# Imprimindo o resultado                           \n",
    "alpha = 0.01\n",
    "w, path = optimize(Xst, y, alpha, eta = 10**-12, iterations = 20000)\n",
    "print (\"Coeficientes finais padronizados: \" + ', '.join(map(lambda x: \"%0.4f\" % x, w)))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a1ade30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desfazendo a Padronização\n",
    "unstandardized_betas = w[:-1] / originanal_stds\n",
    "unstandardized_bias  = w[-1]-np.sum((original_means / originanal_stds) * w[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4d978c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    bias:  36.4595\n",
      "    CRIM:  -0.1080\n",
      "      ZN:   0.0464\n",
      "   INDUS:   0.0206\n",
      "    CHAS:   2.6867\n",
      "     NOX: -17.7666\n",
      "      RM:   3.8099\n",
      "     AGE:   0.0007\n",
      "     DIS:  -1.4756\n",
      "     RAD:   0.3060\n",
      "     TAX:  -0.0123\n",
      " PTRATIO:  -0.9527\n",
      "       B:   0.0093\n",
      "   LSTAT:  -0.5248\n"
     ]
    }
   ],
   "source": [
    "# Imprimindo o resultado\n",
    "print ('%8s: %8.4f' % ('bias', unstandardized_bias))\n",
    "for beta,varname in zip(unstandardized_betas, variables):\n",
    "    print ('%8s: %8.4f' % (varname, beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06535d1",
   "metadata": {},
   "source": [
    "## Importância dos Atributos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e0d1a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um modelo\n",
    "modelo = linear_model.LinearRegression(normalize = False, fit_intercept = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffbe673d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression(normalize=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression(normalize=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression(normalize=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinando o modelo com dados não padronizados (em escalas diferentes)\n",
    "modelo.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6766ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.767 NOX\n",
      " 3.810 RM\n",
      " 2.687 CHAS\n",
      " 1.476 DIS\n",
      " 0.953 PTRATIO\n",
      " 0.525 LSTAT\n",
      " 0.306 RAD\n",
      " 0.108 CRIM\n",
      " 0.046 ZN\n",
      " 0.021 INDUS\n",
      " 0.012 TAX\n",
      " 0.009 B\n",
      " 0.001 AGE\n"
     ]
    }
   ],
   "source": [
    "# Imprimindo os coeficientes e as variáveis\n",
    "# coef,var extrai os atributos mais relevantes por ordem de importancia\n",
    "for coef, var in sorted(zip(map(abs, modelo.coef_), dataset.columns[:-1]), reverse = True):\n",
    "    print (\"%6.3f %s\" % (coef,var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6d57b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padronizando os dados\n",
    "standardization = StandardScaler()\n",
    "Stand_coef_linear_reg = make_pipeline(standardization, modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6af142b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;linearregression&#x27;, LinearRegression(normalize=False))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;linearregression&#x27;, LinearRegression(normalize=False))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression(normalize=False)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('linearregression', LinearRegression(normalize=False))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinando o modelo com dados padronizados (na mesma escala)\n",
    "Stand_coef_linear_reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0c2a543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3.744 LSTAT\n",
      " 3.104 DIS\n",
      " 2.674 RM\n",
      " 2.662 RAD\n",
      " 2.077 TAX\n",
      " 2.061 PTRATIO\n",
      " 2.057 NOX\n",
      " 1.082 ZN\n",
      " 0.928 CRIM\n",
      " 0.849 B\n",
      " 0.682 CHAS\n",
      " 0.141 INDUS\n",
      " 0.019 AGE\n"
     ]
    }
   ],
   "source": [
    "# Imprimindo os coeficientes e as variáveis\n",
    "for coef, var in sorted(zip(map(abs, Stand_coef_linear_reg.steps[1][1].coef_), dataset.columns[:-1]), reverse = True):\n",
    "    print (\"%6.3f %s\" % (coef,var))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8796a54c",
   "metadata": {},
   "source": [
    "### Usando o R Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65f07b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = linear_model.LinearRegression(normalize = False, fit_intercept = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5763869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_est(X,y):\n",
    "    return r2_score(y, modelo.fit(X,y).predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a79622e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficiente R2: 0.741\n"
     ]
    }
   ],
   "source": [
    "print ('Coeficiente R2: %0.3f' %  r2_est(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce16c814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.056 LSTAT\n",
      " 0.044 RM\n",
      " 0.029 DIS\n",
      " 0.028 PTRATIO\n",
      " 0.011 NOX\n",
      " 0.011 RAD\n",
      " 0.006 B\n",
      " 0.006 ZN\n",
      " 0.006 CRIM\n",
      " 0.006 TAX\n",
      " 0.005 CHAS\n",
      " 0.000 INDUS\n",
      " 0.000 AGE\n"
     ]
    }
   ],
   "source": [
    "# Gera o impacto de cada atributo no R2\n",
    "r2_impact = list()\n",
    "for j in range(X.shape[1]):\n",
    "    selection = [i for i in range(X.shape[1]) if i!=j]\n",
    "    r2_impact.append(((r2_est(X,y) - r2_est(X.values[:,selection],y)), dataset.columns[j]))\n",
    "    \n",
    "for imp, varname in sorted(r2_impact, reverse = True):\n",
    "    print ('%6.3f %s' %  (imp, varname))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08a19eb",
   "metadata": {},
   "source": [
    "### Fazendo Previsões com o Modelo de Regressão Linear Múltipla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5393b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f55bdd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataset\n",
    "boston = load_boston() \n",
    "dataset = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "dataset['target'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef990367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston housing dataset tem 506 observações com 14 variáveis cada uma.\n"
     ]
    }
   ],
   "source": [
    "# Formato do Dataset\n",
    "print(\"Boston housing dataset tem {} observações com {} variáveis cada uma.\".format(*dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3cb9935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ade8deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coletando x e y\n",
    "# Usaremos como variáveis explanatórias somente as 4 variáveis mais relevantes\n",
    "X = dataset[['LSTAT', 'RM', 'DIS', 'PTRATIO']]\n",
    "y = dataset['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4aa9852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão em dados de treino e de teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "169778ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o modelo\n",
    "modelo = LinearRegression(normalize = False, fit_intercept = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e20816e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina o modelo\n",
    "modelo_v2 = modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3829228b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6347923449246606"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcula a métrica R2 do nosso modelo\n",
    "r2_score(y_test, modelo_v2.fit(X_train, y_train).predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "047f2ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa Média de Ocupação Para a Casa: [33.65282404]\n"
     ]
    }
   ],
   "source": [
    "# Produz a matriz com os novos dados de entrada para a previsão\n",
    "LSTAT = 5\n",
    "RM = 8\n",
    "DIS = 6\n",
    "PTRATIO = 19\n",
    "\n",
    "# Lista com os valores das variáveis\n",
    "dados_nova_casa = [LSTAT, RM, DIS, PTRATIO]\n",
    "\n",
    "# Reshape\n",
    "Xp = np.array(dados_nova_casa).reshape(1, -1)\n",
    "\n",
    "# Previsão\n",
    "print(\"Taxa Média de Ocupação Para a Casa:\", modelo_v2.predict(Xp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
